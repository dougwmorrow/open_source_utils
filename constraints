import re
import sqlparse
from sqlparse import sql, tokens as T
from typing import Dict, List, Optional, Tuple, Set
from collections import OrderedDict

class TSQLToPandasConverter:
    def __init__(self):
        self.table_aliases = {}
        self.joins = []
        self.pandas_code = []
        self.temp_tables = {}  # Track temporary tables
        self.cte_definitions = {}  # Track CTE definitions
        self.variables = {}  # Track variable declarations
        
    def convert_sql_to_pandas(self, sql_query: str) -> str:
        """
        Main method to convert T-SQL query to Pandas equivalent
        """
        self.reset_state()
        
        # Handle multiple statements
        statements = self.split_statements(sql_query)
        all_pandas_code = []
        
        for i, statement in enumerate(statements):
            if not statement.strip():
                continue
                
            # Add statement separator
            if i > 0:
                all_pandas_code.append(f"\n# --- Statement {i + 1} ---")
            
            try:
                parsed = sqlparse.parse(statement)[0]
                statement_code = self.process_statement(parsed, statement)
                all_pandas_code.append(statement_code)
            except Exception as e:
                all_pandas_code.append(f"# Error parsing statement: {str(e)}")
                all_pandas_code.append(f"# Original statement: {statement}")
        
        return '\n'.join(all_pandas_code)
    
    def split_statements(self, sql_query: str) -> List[str]:
        """Split SQL into individual statements"""
        # Simple statement splitting - could be enhanced
        statements = []
        current_statement = ""
        
        for line in sql_query.split('\n'):
            line = line.strip()
            if line.endswith(';'):
                current_statement += line[:-1]  # Remove semicolon
                if current_statement.strip():
                    statements.append(current_statement)
                current_statement = ""
            else:
                current_statement += line + " "
        
        # Add remaining statement if no semicolon
        if current_statement.strip():
            statements.append(current_statement)
        
        return statements
    
    def reset_state(self):
        """Reset converter state for new query"""
        self.table_aliases = {}
        self.joins = []
        self.pandas_code = []
        self.temp_tables = {}
        self.cte_definitions = {}
        self.variables = {}
    
    def process_statement(self, parsed_statement, original_statement: str) -> str:
        """Process individual SQL statement"""
        statement_type = self.identify_statement_type(parsed_statement, original_statement)
        
        if statement_type == 'CTE':
            return self.handle_cte_statement(parsed_statement, original_statement)
        elif statement_type == 'CREATE_TEMP':
            return self.handle_create_temp_table(parsed_statement, original_statement)
        elif statement_type == 'DROP':
            return self.handle_drop_statement(parsed_statement, original_statement)
        elif statement_type == 'TRUNCATE':
            return self.handle_truncate_statement(parsed_statement, original_statement)
        elif statement_type == 'INSERT':
            return self.handle_insert_statement(parsed_statement, original_statement)
        elif statement_type == 'UPDATE':
            return self.handle_update_statement(parsed_statement, original_statement)
        elif statement_type == 'DELETE':
            return self.handle_delete_statement(parsed_statement, original_statement)
        elif statement_type == 'DECLARE':
            return self.handle_declare_statement(parsed_statement, original_statement)
        elif statement_type == 'SELECT':
            return self.handle_select_statement(parsed_statement, original_statement)
        else:
            return f"# Unsupported statement type: {statement_type}\n# Original: {original_statement}"
    
    def identify_statement_type(self, parsed_statement, original_statement: str) -> str:
        """Identify the type of SQL statement"""
        original_upper = original_statement.upper().strip()
        
        if original_upper.startswith('WITH '):
            return 'CTE'
        elif 'CREATE' in original_upper and ('#' in original_upper or 'TEMP' in original_upper):
            return 'CREATE_TEMP'
        elif original_upper.startswith('DROP '):
            return 'DROP'
        elif original_upper.startswith('TRUNCATE '):
            return 'TRUNCATE'
        elif original_upper.startswith('INSERT '):
            return 'INSERT'
        elif original_upper.startswith('UPDATE '):
            return 'UPDATE'
        elif original_upper.startswith('DELETE '):
            return 'DELETE'
        elif original_upper.startswith('DECLARE '):
            return 'DECLARE'
        elif original_upper.startswith('SELECT '):
            return 'SELECT'
        else:
            return 'UNKNOWN'
    
    def handle_cte_statement(self, parsed_statement, original_statement: str) -> str:
        """Handle Common Table Expression (CTE)"""
        code_lines = []
        code_lines.append("# Common Table Expression (CTE)")
        
        # Parse CTE structure
        cte_pattern = r'WITH\s+(\w+)\s+AS\s*\(\s*(.*?)\s*\)\s*(SELECT.*)'
        match = re.search(cte_pattern, original_statement, re.IGNORECASE | re.DOTALL)
        
        if match:
            cte_name = match.group(1)
            cte_query = match.group(2)
            main_query = match.group(3)
            
            # Store CTE definition
            self.cte_definitions[cte_name] = cte_query
            
            code_lines.append(f"# Define CTE: {cte_name}")
            cte_code = self.convert_select_query(cte_query)
            code_lines.append(f"{cte_name.lower()}_df = {cte_code}")
            code_lines.append("")
            
            # Process main query
            code_lines.append("# Main query using CTE")
            main_code = self.convert_select_query(main_query, cte_name)
            code_lines.append(f"result_df = {main_code}")
        else:
            # Handle multiple CTEs
            code_lines.append("# Multiple CTEs - manual parsing required")
            code_lines.append(f"# Original CTE: {original_statement}")
        
        return '\n'.join(code_lines)
    
    def handle_create_temp_table(self, parsed_statement, original_statement: str) -> str:
        """Handle CREATE temporary table"""
        code_lines = []
        
        # Extract table name
        temp_table_pattern = r'CREATE.*?(?:TABLE|#)?\s+(#?\w+)\s*\((.*?)\)'
        match = re.search(temp_table_pattern, original_statement, re.IGNORECASE | re.DOTALL)
        
        if match:
            table_name = match.group(1).replace('#', 'temp_')
            columns_def = match.group(2)
            
            # Store temp table
            self.temp_tables[table_name] = columns_def
            
            code_lines.append(f"# Create temporary table: {table_name}")
            
            # Parse column definitions
            columns = self.parse_column_definitions(columns_def)
            
            if columns:
                code_lines.append(f"# Define {table_name} structure")
                code_lines.append(f"{table_name} = pd.DataFrame({{")
                for col_name, col_type in columns.items():
                    pandas_type = self.sql_type_to_pandas(col_type)
                    code_lines.append(f"    '{col_name}': pd.Series([], dtype='{pandas_type}'),")
                code_lines.append("})")
            else:
                code_lines.append(f"{table_name} = pd.DataFrame()")
        else:
            # Handle CREATE TABLE AS SELECT
            create_as_pattern = r'CREATE.*?(?:TABLE|#)?\s+(#?\w+)\s+AS\s+(SELECT.*)'
            as_match = re.search(create_as_pattern, original_statement, re.IGNORECASE | re.DOTALL)
            
            if as_match:
                table_name = as_match.group(1).replace('#', 'temp_')
                select_query = as_match.group(2)
                
                code_lines.append(f"# Create temporary table from SELECT: {table_name}")
                select_code = self.convert_select_query(select_query)
                code_lines.append(f"{table_name} = {select_code}")
                
                self.temp_tables[table_name] = "from_select"
            else:
                code_lines.append(f"# Could not parse CREATE statement: {original_statement}")
        
        return '\n'.join(code_lines)
    
    def handle_drop_statement(self, parsed_statement, original_statement: str) -> str:
        """Handle DROP statement"""
        code_lines = []
        
        # Extract what's being dropped
        drop_pattern = r'DROP\s+(TABLE|INDEX|VIEW|PROCEDURE)\s+(?:IF\s+EXISTS\s+)?(.+)'
        match = re.search(drop_pattern, original_statement, re.IGNORECASE)
        
        if match:
            object_type = match.group(1).upper()
            object_name = match.group(2).strip()
            
            if object_type == 'TABLE':
                # Clean table name
                clean_name = self.clean_identifier(object_name).replace('#', 'temp_')
                
                code_lines.append(f"# Drop table: {object_name}")
                code_lines.append(f"# Remove DataFrame from memory")
                code_lines.append(f"try:")
                code_lines.append(f"    del {clean_name}")
                code_lines.append(f"except NameError:")
                code_lines.append(f"    pass  # Table doesn't exist")
                
                # Remove from temp tables tracking
                if clean_name in self.temp_tables:
                    del self.temp_tables[clean_name]
                    
            else:
                code_lines.append(f"# Drop {object_type}: {object_name}")
                code_lines.append(f"# Note: {object_type} operations not directly applicable to Pandas")
        else:
            code_lines.append(f"# Could not parse DROP statement: {original_statement}")
        
        return '\n'.join(code_lines)
    
    def handle_truncate_statement(self, parsed_statement, original_statement: str) -> str:
        """Handle TRUNCATE statement"""
        code_lines = []
        
        # Extract table name
        truncate_pattern = r'TRUNCATE\s+TABLE\s+(.+)'
        match = re.search(truncate_pattern, original_statement, re.IGNORECASE)
        
        if match:
            table_name = self.clean_identifier(match.group(1)).replace('#', 'temp_')
            
            code_lines.append(f"# Truncate table: {table_name}")
            code_lines.append(f"# Clear all data but keep structure")
            code_lines.append(f"if '{table_name}' in locals():")
            code_lines.append(f"    {table_name} = {table_name}.iloc[0:0].copy()  # Keep structure, remove data")
            code_lines.append(f"else:")
            code_lines.append(f"    print('Table {table_name} does not exist')")
        else:
            code_lines.append(f"# Could not parse TRUNCATE statement: {original_statement}")
        
        return '\n'.join(code_lines)
    
    def handle_insert_statement(self, parsed_statement, original_statement: str) -> str:
        """Handle INSERT statement"""
        code_lines = []
        
        # INSERT INTO table VALUES
        values_pattern = r'INSERT\s+INTO\s+(.+?)\s*(?:\(([^)]+)\))?\s*VALUES\s*\((.+)\)'
        values_match = re.search(values_pattern, original_statement, re.IGNORECASE | re.DOTALL)
        
        # INSERT INTO table SELECT
        select_pattern = r'INSERT\s+INTO\s+(.+?)\s*(?:\(([^)]+)\))?\s*(SELECT.*)'
        select_match = re.search(select_pattern, original_statement, re.IGNORECASE | re.DOTALL)
        
        if values_match:
            table_name = self.clean_identifier(values_match.group(1)).replace('#', 'temp_')
            columns = values_match.group(2)
            values = values_match.group(3)
            
            code_lines.append(f"# Insert values into {table_name}")
            
            if columns:
                col_list = [self.clean_identifier(c.strip()) for c in columns.split(',')]
                val_list = [v.strip().strip("'\"") for v in values.split(',')]
                
                code_lines.append(f"new_row = pd.DataFrame({{")
                for col, val in zip(col_list, val_list):
                    code_lines.append(f"    '{col}': [{val}],")
                code_lines.append(f"}})")
            else:
                code_lines.append(f"# Insert into all columns")
                val_list = [v.strip().strip("'\"") for v in values.split(',')]
                code_lines.append(f"new_row = pd.DataFrame([{val_list}])")
            
            code_lines.append(f"{table_name} = pd.concat([{table_name}, new_row], ignore_index=True)")
            
        elif select_match:
            table_name = self.clean_identifier(select_match.group(1)).replace('#', 'temp_')
            columns = select_match.group(2)
            select_query = select_match.group(3)
            
            code_lines.append(f"# Insert SELECT results into {table_name}")
            select_code = self.convert_select_query(select_query)
            code_lines.append(f"insert_data = {select_code}")
            code_lines.append(f"{table_name} = pd.concat([{table_name}, insert_data], ignore_index=True)")
        else:
            code_lines.append(f"# Could not parse INSERT statement: {original_statement}")
        
        return '\n'.join(code_lines)
    
    def handle_update_statement(self, parsed_statement, original_statement: str) -> str:
        """Handle UPDATE statement"""
        code_lines = []
        
        # Basic UPDATE pattern
        update_pattern = r'UPDATE\s+(.+?)\s+SET\s+(.+?)(?:\s+WHERE\s+(.+))?'
        match = re.search(update_pattern, original_statement, re.IGNORECASE | re.DOTALL)
        
        if match:
            table_name = self.clean_identifier(match.group(1)).replace('#', 'temp_')
            set_clause = match.group(2)
            where_clause = match.group(3) if match.group(3) else None
            
            code_lines.append(f"# Update {table_name}")
            
            # Parse SET clause
            set_pairs = [pair.strip() for pair in set_clause.split(',')]
            
            if where_clause:
                where_pandas = self.convert_where_clause(where_clause)
                code_lines.append(f"# Apply WHERE condition: {where_clause}")
                code_lines.append(f"mask = {table_name}.eval('{where_pandas}')")
            else:
                code_lines.append(f"# Update all rows")
                code_lines.append(f"mask = True")
            
            for set_pair in set_pairs:
                if '=' in set_pair:
                    column, value = set_pair.split('=', 1)
                    column = self.clean_identifier(column.strip())
                    value = value.strip().strip("'\"")
                    code_lines.append(f"{table_name}.loc[mask, '{column}'] = {value}")
        else:
            code_lines.append(f"# Could not parse UPDATE statement: {original_statement}")
        
        return '\n'.join(code_lines)

    
    def handle_delete_statement(self, parsed_statement, original_statement: str) -> str:
        """Handle DELETE statement"""
        code_lines = []
        
        # DELETE pattern
        delete_pattern = r'DELETE\s+FROM\s+(.+?)(?:\s+WHERE\s+(.+))?'
        match = re.search(delete_pattern, original_statement, re.IGNORECASE | re.DOTALL)
        
        if match:
            table_name = self.clean_identifier(match.group(1)).replace('#', 'temp_')
            where_clause = match.group(2) if match.group(2) else None
            
            code_lines.append(f"# Delete from {table_name}")
            
            if where_clause:
                where_pandas = self.convert_where_clause(where_clause)
                code_lines.append(f"# Apply WHERE condition: {where_clause}")
                code_lines.append(f"mask = ~{table_name}.eval('{where_pandas}')  # Keep rows that DON'T match")
                code_lines.append(f"{table_name} = {table_name}[mask].reset_index(drop=True)")
            else:
                code_lines.append(f"# Delete all rows")
                code_lines.append(f"{table_name} = {table_name}.iloc[0:0].copy()  # Keep structure, remove data")
        else:
            code_lines.append(f"# Could not parse DELETE statement: {original_statement}")
        
        return '\n'.join(code_lines)
    
    def handle_declare_statement(self, parsed_statement, original_statement: str) -> str:
        """Handle DECLARE statement for variables"""
        code_lines = []
        
        # DECLARE pattern
        declare_pattern = r'DECLARE\s+(@\w+)\s+(\w+)(?:\s*=\s*(.+))?'
        match = re.search(declare_pattern, original_statement, re.IGNORECASE)
        
        if match:
            var_name = match.group(1).replace('@', 'var_')
            var_type = match.group(2)
            var_value = match.group(3) if match.group(3) else None
            
            code_lines.append(f"# Declare variable: {match.group(1)}")
            
            if var_value:
                # Clean the value
                clean_value = var_value.strip().strip("'\"")
                if var_type.upper() in ['INT', 'INTEGER', 'BIGINT']:
                    code_lines.append(f"{var_name} = {clean_value}")
                elif var_type.upper() in ['VARCHAR', 'NVARCHAR', 'CHAR', 'TEXT']:
                    code_lines.append(f"{var_name} = '{clean_value}'")
                elif var_type.upper() in ['DECIMAL', 'FLOAT', 'REAL']:
                    code_lines.append(f"{var_name} = {clean_value}")
                else:
                    code_lines.append(f"{var_name} = '{clean_value}'  # {var_type}")
            else:
                code_lines.append(f"{var_name} = None  # {var_type}")
            
            self.variables[match.group(1)] = var_name
        else:
            code_lines.append(f"# Could not parse DECLARE statement: {original_statement}")
        
        return '\n'.join(code_lines)
    
    def handle_select_statement(self, parsed_statement, original_statement: str) -> str:
        """Handle SELECT statement"""
        code_lines = []
        code_lines.append("import pandas as pd")
        code_lines.append("import numpy as np")
        code_lines.append("")
        
        # Extract components
        components = self.extract_query_components(parsed_statement)
        
        # Generate Pandas code
        pandas_code = self.generate_pandas_code(components)
        code_lines.append(pandas_code)
        
        return '\n'.join(code_lines)
    
    def convert_select_query(self, query: str, cte_context: str = None) -> str:
        """Convert a SELECT query to Pandas code (returns code as string)"""
        try:
            parsed = sqlparse.parse(query)[0]
            components = self.extract_query_components(parsed)
            
            # Build the query step by step
            steps = []
            
            # Handle FROM clause
            if components['from']:
                table_name = self.clean_identifier(components['from'])
                
                # Check if it's a CTE reference
                if cte_context and table_name == cte_context:
                    steps.append(f"{cte_context.lower()}_df")
                # Check if it's a temp table
                elif table_name.replace('#', 'temp_') in self.temp_tables:
                    steps.append(f"{table_name.replace('#', 'temp_')}")
                else:
                    steps.append(f"pd.read_sql_table('{table_name}', connection)")
            
            # Add other operations as method chains
            df_var = "df_temp"
            result_steps = [f"{df_var} = {steps[0] if steps else 'df'}"]
            
            # WHERE clause
            if components['where']:
                where_code = self.convert_where_clause(components['where'])
                result_steps.append(f"{df_var} = {df_var}.query('{where_code}')")
            
            # GROUP BY
            if components['group_by']:
                group_code = self.convert_group_by_simple(components['group_by'], components['select'])
                result_steps.append(f"{df_var} = {group_code.replace('df', df_var)}")
            
            # SELECT (column selection)
            if components['select'] and not components['group_by']:
                select_code = self.convert_select_simple(components['select'])
                if select_code:
                    result_steps.append(f"{df_var} = {select_code.replace('df', df_var)}")
            
            # ORDER BY
            if components['order_by']:
                order_code = self.convert_order_by_simple(components['order_by'])
                result_steps.append(f"{df_var} = {order_code.replace('df', df_var)}")
            
            return f"({'; '.join(result_steps)}; {df_var})[-1]"  # Return the final result
            
        except Exception as e:
            return f"# Error converting SELECT: {str(e)}"
    
    def parse_column_definitions(self, columns_def: str) -> Dict[str, str]:
        """Parse column definitions from CREATE TABLE"""
        columns = {}
        
        # Simple parsing - split by comma and extract name/type
        col_defs = [col.strip() for col in columns_def.split(',')]
        
        for col_def in col_defs:
            parts = col_def.split()
            if len(parts) >= 2:
                col_name = self.clean_identifier(parts[0])
                col_type = parts[1]
                columns[col_name] = col_type
        
        return columns
    
    def sql_type_to_pandas(self, sql_type: str) -> str:
        """Convert SQL data type to Pandas dtype"""
        sql_type_upper = sql_type.upper()
        
        if any(t in sql_type_upper for t in ['INT', 'BIGINT', 'SMALLINT']):
            return 'int64'
        elif any(t in sql_type_upper for t in ['DECIMAL', 'FLOAT', 'REAL', 'NUMERIC']):
            return 'float64'
        elif any(t in sql_type_upper for t in ['VARCHAR', 'CHAR', 'TEXT', 'NVARCHAR']):
            return 'object'
        elif any(t in sql_type_upper for t in ['DATE', 'DATETIME', 'TIMESTAMP']):
            return 'datetime64[ns]'
        elif 'BIT' in sql_type_upper:
            return 'bool'
        else:
            return 'object'
    
    def convert_select_simple(self, select_items: List[str]) -> str:
        """Simple SELECT conversion returning code string"""
        select_clause = ' '.join(select_items).strip()
        
        if select_clause.upper().startswith('*'):
            return ""  # No change needed
        
        columns = self.parse_select_items(select_clause)
        if columns:
            column_list = ', '.join([f"'{col}'" for col in columns])
            return f"df[[{column_list}]]"
        
        return ""
    
    def convert_group_by_simple(self, group_items: List[str], select_items: List[str]) -> str:
        """Simple GROUP BY conversion returning code string"""
        group_clause = ' '.join(group_items).strip()
        group_columns = [self.clean_identifier(col.strip()) for col in group_clause.split(',')]
        
        select_clause = ' '.join(select_items).strip()
        agg_functions = self.detect_aggregations(select_clause)
        
        if agg_functions:
            agg_dict = ', '.join([f"'{col}': '{func}'" for col, func in agg_functions.items()])
            return f"df.groupby({group_columns}).agg({{{agg_dict}}}).reset_index()"
        else:
            return f"df.groupby({group_columns}).size().reset_index(name='count')"
    
    def convert_order_by_simple(self, order_items: List[str]) -> str:
        """Simple ORDER BY conversion returning code string"""
        order_clause = ' '.join(order_items).strip()
        
        order_columns = []
        ascending = []
        
        items = [item.strip() for item in order_clause.split(',')]
        for item in items:
            parts = item.split()
            column = self.clean_identifier(parts[0])
            order_columns.append(column)
            
            if len(parts) > 1 and parts[1].upper() == 'DESC':
                ascending.append(False)
            else:
                ascending.append(True)
        
        if len(order_columns) == 1:
            return f"df.sort_values('{order_columns[0]}', ascending={str(ascending[0]).lower()})"
        else:
            return f"df.sort_values({order_columns}, ascending={ascending})"
    
    # Include all the previous methods (extract_query_components, generate_pandas_code, etc.)
    # [Previous methods remain the same - copying them here for completeness]
    
    def extract_query_components(self, parsed_query) -> Dict:
        """Extract key components from parsed SQL"""
        components = {
            'select': [],
            'from': None,
            'joins': [],
            'where': None,
            'group_by': [],
            'having': None,
            'order_by': [],
            'limit': None
        }
        
        current_keyword = None
        
        for token in parsed_query.flatten():
            if token.ttype is T.Keyword:
                keyword_upper = token.value.upper()
                if keyword_upper in ['SELECT', 'FROM', 'WHERE', 'GROUP', 'HAVING', 'ORDER', 'LIMIT', 'TOP']:
                    current_keyword = keyword_upper
                elif keyword_upper in ['JOIN', 'INNER', 'LEFT', 'RIGHT', 'FULL']:
                    current_keyword = 'JOIN'
                elif keyword_upper == 'BY' and current_keyword in ['GROUP', 'ORDER']:
                    continue
            elif token.ttype not in [T.Whitespace, T.Newline] and current_keyword:
                self.add_component_token(components, current_keyword, token)
        
        return components
    
    def add_component_token(self, components: Dict, keyword: str, token):
        """Add token to appropriate component"""
        if keyword == 'SELECT':
            components['select'].append(token.value)
        elif keyword == 'FROM':
            if not components['from']:
                components['from'] = token.value
        elif keyword == 'WHERE':
            if not components['where']:
                components['where'] = token.value
            else:
                components['where'] += ' ' + token.value
        elif keyword == 'GROUP':
            components['group_by'].append(token.value)
        elif keyword == 'ORDER':
            components['order_by'].append(token.value)
        elif keyword == 'JOIN':
            components['joins'].append(token.value)
    
    def generate_pandas_code(self, components: Dict) -> str:
        """Generate Pandas code from extracted components"""
        code_lines = []
        
        # Handle FROM clause
        if components['from']:
            main_table = self.clean_identifier(components['from'])
            code_lines.append(f"# Load main table")
            code_lines.append(f"df = pd.read_sql_table('{main_table}', connection)")
            code_lines.append("# Or load from CSV: df = pd.read_csv('{main_table}.csv')")
            code_lines.append("")
        
        # Handle JOINs
        if components['joins']:
            join_code = self.convert_joins(components['joins'])
            code_lines.extend(join_code)
        
        # Handle WHERE clause
        if components['where']:
            where_code = self.convert_where_clause(components['where'])
            code_lines.append(f"# Apply WHERE conditions")
            code_lines.append(f"df = df.query('{where_code}')")
            code_lines.append("")
        
        # Handle GROUP BY
        if components['group_by']:
            group_code = self.convert_group_by(components['group_by'], components['select'])
            code_lines.extend(group_code)
        
        # Handle SELECT
        if components['select']:
            select_code = self.convert_select(components['select'])
            if not components['group_by']:
                code_lines.extend(select_code)
        
        # Handle ORDER BY
        if components['order_by']:
            order_code = self.convert_order_by(components['order_by'])
            code_lines.extend(order_code)
        
        return '\n'.join(code_lines)
    
    def convert_select(self, select_items: List[str]) -> List[str]:
        """Convert SELECT clause to Pandas column selection"""
        code_lines = []
        
        select_clause = ' '.join(select_items).strip()
        
        if select_clause.upper().startswith('*'):
            code_lines.append("# Select all columns (already selected)")
            return code_lines
        
        columns = self.parse_select_items(select_clause)
        
        if columns:
            code_lines.append("# Select specific columns")
            column_list = ', '.join([f"'{col}'" for col in columns])
            code_lines.append(f"df = df[[{column_list}]]")
            code_lines.append("")
        
        return code_lines
    
    def parse_select_items(self, select_clause: str) -> List[str]:
        """Parse individual SELECT items"""
        items = [item.strip() for item in select_clause.split(',')]
        columns = []
        
        for item in items:
            if ' AS ' in item.upper():
                parts = re.split(r'\s+AS\s+', item, flags=re.IGNORECASE)
                if len(parts) == 2:
                    columns.append(self.clean_identifier(parts[1]))
                else:
                    columns.append(self.clean_identifier(item))
            else:
                columns.append(self.clean_identifier(item))
        
        return columns
    
    def convert_where_clause(self, where_clause: str) -> str:
        """Convert WHERE clause to Pandas query format"""
        pandas_where = where_clause
        
        replacements = {
            ' = ': ' == ',
            ' <> ': ' != ',
            ' AND ': ' & ',
            ' OR ': ' | ',
            ' NOT ': ' ~ ',
            'IS NULL': '.isna()',
            'IS NOT NULL': '.notna()'
        }
        
        for sql_op, pandas_op in replacements.items():
            pandas_where = re.sub(sql_op, pandas_op, pandas_where, flags=re.IGNORECASE)
        
        return pandas_where
    
    def convert_group_by(self, group_items: List[str], select_items: List[str]) -> List[str]:
        """Convert GROUP BY clause to Pandas groupby"""
        code_lines = []
        
        group_clause = ' '.join(group_items).strip()
        group_columns = [self.clean_identifier(col.strip()) for col in group_clause.split(',')]
        
        select_clause = ' '.join(select_items).strip()
        agg_functions = self.detect_aggregations(select_clause)
        
        code_lines.append("# Group by operation")
        
        if agg_functions:
            code_lines.append(f"df = df.groupby({group_columns}).agg({{")
            for col, func in agg_functions.items():
                code_lines.append(f"    '{col}': '{func}',")
            code_lines.append("}).reset_index()")
        else:
            code_lines.append(f"df = df.groupby({group_columns}).size().reset_index(name='count')")
        
        code_lines.append("")
        return code_lines
    
    def detect_aggregations(self, select_clause: str) -> Dict[str, str]:
        """Detect aggregation functions in SELECT clause"""
        agg_functions = {}
        
        agg_patterns = {
            r'COUNT\s*\(\s*([^)]+)\s*\)': 'count',
            r'SUM\s*\(\s*([^)]+)\s*\)': 'sum',
            r'AVG\s*\(\s*([^)]+)\s*\)': 'mean',
            r'MIN\s*\(\s*([^)]+)\s*\)': 'min',
            r'MAX\s*\(\s*([^)]+)\s*\)': 'max'
        }
        
        for pattern, func in agg_patterns.items():
            matches = re.finditer(pattern, select_clause, re.IGNORECASE)
            for match in matches:
                column = self.clean_identifier(match.group(1))
                if column != '*':
                    agg_functions[column] = func
        
        return agg_functions
    
    def convert_order_by(self, order_items: List[str]) -> List[str]:
        """Convert ORDER BY clause to Pandas sort_values"""
        code_lines = []
        
        order_clause = ' '.join(order_items).strip()
        
        order_columns = []
        ascending = []
        
        items = [item.strip() for item in order_clause.split(',')]
        for item in items:
            parts = item.split()
            column = self.clean_identifier(parts[0])
            order_columns.append(column)
            
            if len(parts) > 1 and parts[1].upper() == 'DESC':
                ascending.append(False)
            else:
                ascending.append(True)
        
        code_lines.append("# Sort results")
        if len(order_columns) == 1:
            asc_val = str(ascending[0]).lower()
            code_lines.append(f"df = df.sort_values('{order_columns[0]}', ascending={asc_val})")
        else:
            columns_str = str(order_columns)
            ascending_str = str(ascending)
            code_lines.append(f"df = df.sort_values({columns_str}, ascending={ascending_str})")
        
        code_lines.append("")
        return code_lines
    
    def convert_joins(self, join_items: List[str]) -> List[str]:
        """Convert JOIN clauses to Pandas merge operations"""
        code_lines = []
        
        join_clause = ' '.join(join_items)
        
        code_lines.append("# JOIN operations")
        code_lines.append("# Note: Load additional tables and use pd.merge()")
        code_lines.append(f"# Original JOIN: {join_clause}")
        code_lines.append("# df = pd.merge(df, other_df, on='key_column', how='inner')")
        code_lines.append("")
        
        return code_lines
    
    def clean_identifier(self, identifier: str) -> str:
        """Clean SQL identifier (remove brackets, quotes, etc.)"""
        if not identifier:
            return identifier
        
        cleaned = identifier.strip()
        cleaned = re.sub(r'[\[\]"`]', '', cleaned)
        
        return cleaned

# Enhanced test function with new features
def test_enhanced_converter():
    """Test the enhanced converter with CTEs, temp tables, etc."""
    converter = TSQLToPandasConverter()
    
    test_queries = [
        # CTE Example
        """
        WITH RegionalSales AS (
            SELECT Region, SUM(Sales) as TotalSales
            FROM SalesData
            WHERE Year = 2023
            GROUP BY Region
        )
        SELECT Region, TotalSales
        FROM RegionalSales
        WHERE TotalSales > 100000
        ORDER BY TotalSales DESC;
        """,
        
        # Temp Table Example
        """
        CREATE TABLE #TempCustomers (
            CustomerID INT,
            CustomerName VARCHAR(100),
            Region VARCHAR(50)
        );
        
        INSERT INTO #TempCustomers VALUES (1, 'John Doe', 'North');
        INSERT INTO #TempCustomers VALUES (2, 'Jane Smith', 'South');
        
        SELECT * FROM #TempCustomers WHERE Region = 'North';
        
        DROP TABLE #TempCustomers;
        """,
        
        # Variable Declaration and Usage
        """
        DECLARE @MinSales INT = 50000;
        DECLARE @Region VARCHAR(20) = 'West';
        
        SELECT CustomerID, TotalSales
        FROM CustomerSummary
        WHERE TotalSales > @MinSales AND Region = @Region;
        """,
        
        # UPDATE and DELETE
        """
        UPDATE Products
        SET Price = Price * 1.1
        WHERE Category = 'Electronics';
        
        DELETE FROM Orders
        WHERE OrderDate < '2023-01-01';
        
        TRUNCATE TABLE TempLog;
        """
    ]
    
    print("Enhanced T-SQL to Pandas Converter - Test Results")
    print("=" * 60)
    
    for i, query in enumerate(test_queries, 1):
        print(f"\n--- Test Query {i} ---")
        print("Original SQL:")
        print(query.strip())
        print("\nConverted Pandas Code:")
        print(converter.convert_sql_to_pandas(query))
        print("-" * 40)

if __name__ == "__main__":
    test_enhanced_converter()